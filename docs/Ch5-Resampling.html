<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Chapter 5 - Resampling Methods</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Chapter 5 - Resampling Methods</h1>

</div>


<p>Load the required packages and data.</p>
<pre class="r"><code>library(boot)
my_data &lt;- load(&quot;..\\data\\5.R.RData&quot;)
sample_dataset &lt;- Xy
Xy &lt;- NULL</code></pre>
<p>Train a simple linear model and print it’s summary to get the coefficient for X1</p>
<pre class="r"><code>my_model &lt;- lm(y~X1+X2, data=sample_dataset)

summary(my_model)$coefficients</code></pre>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) 0.2658349 0.01988032 13.371758 1.249278e-37
## X1          0.1453263 0.02593295  5.603925 2.711026e-08
## X2          0.3133670 0.02922671 10.721938 1.843565e-25</code></pre>
<p>Plot the variables against each other - each line represents a column from the dataset.</p>
<pre class="r"><code>matplot(sample_dataset,type=&quot;l&quot;)</code></pre>
<p><img src="Ch5-Resampling_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>This plot shows that there’s autocorrelation in the dataset - this means that the data is correlated with a lagged version of itself. For example, yesterday’s temperature might be a good predictor of today’s temperature. We can see this is the plot as smooth, up and down curves.</p>
<p>Lets look at the plot if we randomly re-order the rows.</p>
<pre class="r"><code>new_index &lt;- sample(1:1000, size = 1000, replace = FALSE)
sample_dataset2 &lt;- sample_dataset[new_index,]
matplot(sample_dataset2,type=&quot;l&quot;)</code></pre>
<p><img src="Ch5-Resampling_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>We can use the <code>acf</code> function to test the correlation between a variable and lagged versions of itself.</p>
<pre class="r"><code>acf(sample_dataset$X1,  lag.max = 5, plot = FALSE)</code></pre>
<pre><code>## 
## Autocorrelations of series &#39;sample_dataset$X1&#39;, by lag
## 
##     0     1     2     3     4     5 
## 1.000 0.997 0.993 0.988 0.981 0.974</code></pre>
<pre class="r"><code>acf(sample_dataset2$X1, lag.max = 5, plot = FALSE)</code></pre>
<pre><code>## 
## Autocorrelations of series &#39;sample_dataset2$X1&#39;, by lag
## 
##      0      1      2      3      4      5 
##  1.000  0.003 -0.014  0.025 -0.030 -0.052</code></pre>
<p>This very strong autocorrelation effectively reduces our sample size - we think we have 1000 points but each point is very similar to the points before and after it. The summary(my_model) estimates the SE with the assumption that we have 1000 iid data points, causing it to be overconfident and give too small an estimate for the error.</p>
<div id="bootstrapping" class="section level1">
<h1>Bootstrapping</h1>
<p>First we create a function which outputs the estimate for the coefficient of X1. The <code>index</code> argument enables the creation of a bootstrapped sample. The <code>boot</code> function feeds a vector into <code>index</code> which tells it which rows to use from the input dataset.</p>
<pre class="r"><code>extract_coefficient &lt;- function(input_data, index){
  my_model &lt;- lm(y~X1+X2, data=input_data[index,])
  my_model$coefficients[2]
}</code></pre>
<p>Now we can apply this function to 100 bootstrapped samples</p>
<pre class="r"><code>my_boot &lt;- boot(sample_dataset, extract_coefficient, R=100)
my_boot</code></pre>
<pre><code>## 
## ORDINARY NONPARAMETRIC BOOTSTRAP
## 
## 
## Call:
## boot(data = sample_dataset, statistic = extract_coefficient, 
##     R = 100)
## 
## 
## Bootstrap Statistics :
##      original       bias    std. error
## t1* 0.1453263 -0.007617779  0.02884282</code></pre>
<p>This boot strap gives a higher estimate of the standard error for X1’s coefficient than <code>summary(my_model)</code> did but it’s still making the assumption that the points are iid, causing it to underestimate the standard error.</p>
<div id="block-bootstrapping" class="section level2">
<h2>Block Bootstrapping</h2>
<p>Here we split data into 100 row chunks, then pick 10 chucks with replacement. This is typically done with time series data since each data point is correlated with the points before and after it (- if you were to select points at random then points would no longer be correlated with the points around them (i.e they’re not independent). We can implement this quite easily using the <code>tsboot</code> (time series bootstrap) function.</p>
<pre class="r"><code>block_boot &lt;- tsboot(tseries = sample_dataset, extract_coefficient, R=100, 
                   l = 100, # This is the size of each block (100 consecutive data points)
                   sim = &quot;fixed&quot;) # This means used blocks of a fixed length
block_boot</code></pre>
<pre><code>## 
## BLOCK BOOTSTRAP FOR TIME SERIES
## 
## Fixed Block Length of 100 
## 
## Call:
## tsboot(tseries = sample_dataset, statistic = extract_coefficient, 
##     R = 100, l = 100, sim = &quot;fixed&quot;)
## 
## 
## Bootstrap Statistics :
##      original      bias    std. error
## t1* 0.1453263 0.005105024   0.2058791</code></pre>
<p>This gives us a new estimate for the standard error which is much larger than the SE given when selecting data points at random. Why is that?</p>
<p>Well the autocorrelation between the points has been preserved since we’re taking chunks of points (so the correlation between consecutive points is maintained).</p>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
